server.port=${PORT:9090}
logging.level.org.atmosphere = warn
spring.mustache.check-template-location = false
spring.profiles.active=dev

# Launch the default browser when starting the application in development mode
vaadin.launch-browser=true

# Workaround for https://github.com/vaadin/hilla/issues/842
spring.devtools.restart.additional-exclude=dev/hilla/openapi.json
# To improve the performance during development.
# For more information https://vaadin.com/docs/flow/spring/tutorial-spring-configuration.html#special-configuration-parameters
vaadin.allowed-packages=com.vaadin,org.vaadin,dev.hilla,com.example.application
spring.jpa.defer-datasource-initialization = true

# LangChain4j properties
#langchain4j.open-ai.streaming-chat-model.api-key=${OPENAI_API_KEY}
#langchain4j.open-ai.streaming-chat-model.model-name=gpt-4-turbo
#langchain4j.open-ai.streaming-chat-model.temperature=0
#langchain4j.open-ai.embedding-model.api-key=${OPENAI_API_KEY}
#langchain4j.open-ai.streaming-chat-model.strict-tools=true
# LangChain4j properties
langchain4j.google-ai-gemini.streaming-chat-model.api-key=${GOOGLE_API_KEY}
langchain4j.google-ai-gemini.streaming-chat-model.model-name=gemini-2.0-flash
langchain4j.google-ai-gemini.streaming-chat-model.temperature=0
langchain4j.google-ai-gemini.embedding-model.model-name=text-embedding-004
langchain4j.google-ai-gemini.embedding-model.api-key=${GOOGLE_API_KEY}
langchain4j.google-ai-gemini.streaming-chat-model.strict-tools=true

# Logging properties
#langchain4j.open-ai.streaming-chat-model.log-requests=true
#langchain4j.open-ai.streaming-chat-model.log-responses=false
langchain4j.google-ai-gemini.streaming-chat-model.log-requests=true
langchain4j.google-ai-gemini.streaming-chat-model.log-responses=false
logging.level.dev.langchain4j=DEBUG
logging.level.dev.ai4j.openai4j=DEBUG
logging.level.ai.djl=OFF
